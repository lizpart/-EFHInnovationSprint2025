{"cells":[{"cellId":"54f21a6d535b4b0c98b7b88d7c061335","cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"54f21a6d535b4b0c98b7b88d7c061335","deepnote_cell_type":"text-cell-h2"},"source":"## Installations","block_group":"0dfae4e9bde34b0ca2fd409b0b252766"},{"cellId":"59b81d237d39481a8df913f3a1e85e40","cell_type":"code","metadata":{"source_hash":"1b12d13f","execution_start":1744268798268,"execution_millis":18742,"execution_context_id":"d04806a7-2f83-4919-84b6-d3558091af9a","cell_id":"59b81d237d39481a8df913f3a1e85e40","deepnote_cell_type":"code"},"source":"!pip install pillow langchain_experimental \"langchain[all]\" langchain.tools matplotlib seaborn openpyxl pandas langchain-community langchain-experimental openai python-dotenv","block_group":"59b81d237d39481a8df913f3a1e85e40","execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pillow in /root/venv/lib/python3.10/site-packages (11.1.0)\nCollecting langchain_experimental\n  Downloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting langchain[all]\n  Downloading langchain-0.3.23-py3-none-any.whl (1.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting langchain.tools\n  Downloading langchain_tools-0.1.34-py3-none-any.whl (8.5 kB)\nRequirement already satisfied: matplotlib in /root/venv/lib/python3.10/site-packages (3.6.3)\nRequirement already satisfied: seaborn in /root/venv/lib/python3.10/site-packages (0.13.2)\nCollecting openpyxl\n  Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.9/250.9 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pandas in /root/venv/lib/python3.10/site-packages (2.1.4)\nCollecting langchain-community\n  Downloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting openai\n  Downloading openai-1.72.0-py3-none-any.whl (643 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m643.9/643.9 kB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting python-dotenv\n  Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\nCollecting langchain-core<0.4.0,>=0.3.28\n  Downloading langchain_core-0.3.51-py3-none-any.whl (423 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.3/423.3 kB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[33mWARNING: langchain 0.3.23 does not provide the extra 'all'\u001b[0m\u001b[33m\n\u001b[0mCollecting langsmith<0.4,>=0.1.17\n  Downloading langsmith-0.3.28-py3-none-any.whl (357 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.7/357.7 kB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting async-timeout<5.0.0,>=4.0.0\n  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\nRequirement already satisfied: requests<3,>=2 in /root/venv/lib/python3.10/site-packages (from langchain[all]) (2.32.3)\nCollecting pydantic<3.0.0,>=2.7.4\n  Downloading pydantic-2.11.3-py3-none-any.whl (443 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.6/443.6 kB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /root/venv/lib/python3.10/site-packages (from langchain[all]) (6.0.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /toolkit-cache/0.2.14/python3.10/kernel-libs/lib/python3.10/site-packages (from langchain[all]) (1.4.42)\nCollecting langchain-text-splitters<1.0.0,>=0.3.8\n  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\nCollecting langchain-openai\n  Downloading langchain_openai-0.3.12-py3-none-any.whl (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /root/venv/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /root/venv/lib/python3.10/site-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: fonttools>=4.22.0 in /root/venv/lib/python3.10/site-packages (from matplotlib) (4.56.0)\nRequirement already satisfied: contourpy>=1.0.1 in /root/venv/lib/python3.10/site-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /root/venv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: numpy>=1.19 in /root/venv/lib/python3.10/site-packages (from matplotlib) (1.25.2)\nRequirement already satisfied: packaging>=20.0 in /root/venv/lib/python3.10/site-packages (from matplotlib) (24.2)\nRequirement already satisfied: pyparsing>=2.2.1 in /root/venv/lib/python3.10/site-packages (from matplotlib) (3.2.1)\nCollecting et-xmlfile\n  Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\nRequirement already satisfied: pytz>=2020.1 in /root/venv/lib/python3.10/site-packages (from pandas) (2025.1)\nRequirement already satisfied: tzdata>=2022.1 in /root/venv/lib/python3.10/site-packages (from pandas) (2025.1)\nCollecting pydantic-settings<3.0.0,>=2.4.0\n  Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\nCollecting httpx-sse<1.0.0,>=0.4.0\n  Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nCollecting dataclasses-json<0.7,>=0.5.7\n  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\nCollecting aiohttp<4.0.0,>=3.8.3\n  Downloading aiohttp-3.11.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /toolkit-cache/0.2.14/python3.10/kernel-libs/lib/python3.10/site-packages (from langchain-community) (9.0.0)\nCollecting numpy>=1.19\n  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting sniffio\n  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\nRequirement already satisfied: typing-extensions<5,>=4.11 in /root/venv/lib/python3.10/site-packages (from openai) (4.12.2)\nRequirement already satisfied: tqdm>4 in /root/venv/lib/python3.10/site-packages (from openai) (4.67.1)\nCollecting distro<2,>=1.7.0\n  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\nCollecting anyio<5,>=3.5.0\n  Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting jiter<1,>=0.4.0\n  Downloading jiter-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.9/352.9 kB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting httpx<1,>=0.23.0\n  Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /root/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\nCollecting aiosignal>=1.1.2\n  Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\nCollecting yarl<2.0,>=1.17.0\n  Downloading yarl-1.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (334 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m334.0/334.0 kB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting aiohappyeyeballs>=2.3.0\n  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\nCollecting multidict<7.0,>=4.5\n  Downloading multidict-6.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (219 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.8/219.8 kB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting propcache>=0.2.0\n  Downloading propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.6/206.6 kB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting frozenlist>=1.1.1\n  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: idna>=2.8 in /root/venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /root/venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\nCollecting typing-inspect<1,>=0.4.0\n  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\nCollecting marshmallow<4.0.0,>=3.18.0\n  Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: certifi in /root/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\nCollecting httpcore==1.*\n  Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting h11<0.15,>=0.13\n  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting jsonpatch<2.0,>=1.33\n  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\nCollecting orjson<4.0.0,>=3.9.14\n  Downloading orjson-3.10.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting requests-toolbelt<2.0.0,>=1.0.0\n  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting zstandard<0.24.0,>=0.23.0\n  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m147.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting typing-inspection>=0.4.0\n  Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\nCollecting pydantic-core==2.33.1\n  Downloading pydantic_core-2.33.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m131.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting annotated-types>=0.6.0\n  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\nRequirement already satisfied: six>=1.5 in /root/venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /root/venv/lib/python3.10/site-packages (from requests<3,>=2->langchain[all]) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /root/venv/lib/python3.10/site-packages (from requests<3,>=2->langchain[all]) (2.3.0)\nRequirement already satisfied: greenlet!=0.4.17 in /toolkit-cache/0.2.14/python3.10/kernel-libs/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain[all]) (3.0.3)\nCollecting tiktoken<1,>=0.7\n  Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting jsonpointer>=1.9\n  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\nRequirement already satisfied: regex>=2022.1.18 in /root/venv/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai->langchain.tools) (2024.11.6)\nCollecting mypy-extensions>=0.3.0\n  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\nInstalling collected packages: zstandard, typing-inspection, sniffio, python-dotenv, pydantic-core, propcache, orjson, numpy, mypy-extensions, multidict, marshmallow, jsonpointer, jiter, httpx-sse, h11, frozenlist, et-xmlfile, distro, async-timeout, annotated-types, aiohappyeyeballs, yarl, typing-inspect, tiktoken, requests-toolbelt, pydantic, openpyxl, jsonpatch, httpcore, anyio, aiosignal, pydantic-settings, httpx, dataclasses-json, aiohttp, openai, langsmith, langchain-core, langchain-text-splitters, langchain-openai, langchain, langchain-community, langchain.tools, langchain_experimental\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.25.2\n    Uninstalling numpy-1.25.2:\n      Successfully uninstalled numpy-1.25.2\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 1.10.21\n    Uninstalling pydantic-1.10.21:\n      Successfully uninstalled pydantic-1.10.21\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nspacy 3.4.4 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 2.11.3 which is incompatible.\nscipy 1.9.3 requires numpy<1.26.0,>=1.18.5, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.16 aiosignal-1.3.2 annotated-types-0.7.0 anyio-4.9.0 async-timeout-4.0.3 dataclasses-json-0.6.7 distro-1.9.0 et-xmlfile-2.0.0 frozenlist-1.5.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 httpx-sse-0.4.0 jiter-0.9.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.23 langchain-community-0.3.21 langchain-core-0.3.51 langchain-openai-0.3.12 langchain-text-splitters-0.3.8 langchain.tools-0.1.34 langchain_experimental-0.3.4 langsmith-0.3.28 marshmallow-3.26.1 multidict-6.4.2 mypy-extensions-1.0.0 numpy-1.26.4 openai-1.72.0 openpyxl-3.1.5 orjson-3.10.16 propcache-0.3.1 pydantic-2.11.3 pydantic-core-2.33.1 pydantic-settings-2.8.1 python-dotenv-1.1.0 requests-toolbelt-1.0.0 sniffio-1.3.1 tiktoken-0.9.0 typing-inspect-0.9.0 typing-inspection-0.4.0 yarl-1.19.0 zstandard-0.23.0\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/38622349-2d2a-48ec-a427-1620609fe3da","content_dependencies":null},{"cellId":"9c3ceb125bee46de874b71084cf7b697","cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"9c3ceb125bee46de874b71084cf7b697","deepnote_cell_type":"text-cell-h2"},"source":"## Import necessary Libraries","block_group":"d852f6fbc3544311b11a2198e34a3d97"},{"cellId":"c116b4ce8fb340ef9b3b06a5dc82738d","cell_type":"code","metadata":{"source_hash":"da1cbed6","execution_start":1744270223125,"execution_millis":2296,"execution_context_id":"1be585ba-1c4c-4a4f-b675-ee7766739c8d","cell_id":"c116b4ce8fb340ef9b3b06a5dc82738d","deepnote_cell_type":"code"},"source":"import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom dotenv import load_dotenv\nfrom langchain_community.llms import OpenAI\nfrom langchain_experimental.agents import create_pandas_dataframe_agent\nfrom langchain_experimental.tools import PythonAstREPLTool\nfrom langchain.agents import AgentType, initialize_agent, load_tools","block_group":"69d4809030dd4ef480230343f13d012f","execution_count":1,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'dotenv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_experimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_pandas_dataframe_agent\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dotenv'"]}],"outputs_reference":"s3:deepnote-cell-outputs-production/a5fa3a20-06b6-4426-b277-616aafa3eb36","content_dependencies":null},{"cellId":"6055607a647d4baca760e1e868424561","cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"6055607a647d4baca760e1e868424561","deepnote_cell_type":"text-cell-h2"},"source":"## Build the SQL2text system","block_group":"973d909f421942eb98bd8b321f1f0149"},{"cellId":"2c164a953cce489e9e1482048b919a4b","cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"2c164a953cce489e9e1482048b919a4b","deepnote_cell_type":"text-cell-p"},"source":"Upon running this application, upload the csv or excel file when prompted. Ensure its uploaded in the Files space in deepnote. Then copy its path from there and paste it in in the text box. Then the next prompt requires you to give it a name. Then you can proceed to query based on your question.","block_group":"ab2c4ee821b04d1db62839d6dce1d6ec"},{"cellId":"d13bb5dd2d4f4d19b1400b06fb5a5e55","cell_type":"code","metadata":{"source_hash":"75c2ea8f","execution_start":1741348314069,"execution_millis":1087205,"execution_context_id":"25c0b634-96ab-48ed-8152-95043367d551","deepnote_to_be_reexecuted":true,"cell_id":"d13bb5dd2d4f4d19b1400b06fb5a5e55","deepnote_cell_type":"code"},"source":"# Load environment variables\nload_dotenv()\n\n# Get API key\nAPI_KEY = \"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\"\n\n# Initialize tools list - we'll populate it after loading data\ntools = []\n\n# ===== DATA HANDLER CLASS =====\nclass DataHandler:\n    def __init__(self):\n        \"\"\"Initialize a data handler to manage CSV datasets.\"\"\"\n        self.dataframes = {}  # Store loaded dataframes\n        self.current_df = None  # Currently active dataframe\n    \n\n    def load_file(self, file_path, name=None, encoding=None):\n        \"\"\"\n        Load a data file (CSV or Excel) into the system.\n        \n        Parameters:\n            file_path (str): Path to the data file\n            name (str, optional): Name to assign to the dataframe\n            encoding (str, optional): File encoding to use for CSV files\n        \"\"\"\n        try:\n            # Check if file exists\n            if not os.path.exists(file_path):\n                return f\"Error: File {file_path} not found.\"\n            \n            # Determine file type based on extension\n            file_extension = os.path.splitext(file_path)[1].lower()\n            \n            # Load the file based on its extension\n            if file_extension in ['.xlsx', '.xls', '.xlsm', '.xlsb']:\n                # Handle Excel files\n                try:\n                    df = pd.read_excel(file_path)\n                    file_type = \"Excel\"\n                except Exception as e:\n                    return f\"Error loading Excel file: {str(e)}\"\n                    \n            elif file_extension in ['.csv', '.txt', '.dat', '.tsv']:\n                # Handle CSV/text files with encoding detection\n                file_type = \"CSV\"\n                if encoding is None:\n                    # Try different encodings\n                    encodings_to_try = ['utf-8', 'latin1', 'ISO-8859-1', 'cp1252']\n                    success = False\n                    \n                    for enc in encodings_to_try:\n                        try:\n                            if file_extension == '.tsv':\n                                df = pd.read_csv(file_path, encoding=enc, sep='\\t')\n                            else:\n                                df = pd.read_csv(file_path, encoding=enc)\n                            encoding = enc\n                            success = True\n                            break\n                        except UnicodeDecodeError:\n                            continue\n                        except Exception as e:\n                            return f\"Error loading file: {str(e)}\"\n                    \n                    if not success:\n                        return \"Error: Could not automatically detect file encoding. Please specify encoding parameter.\"\n                else:\n                    # Use the provided encoding\n                    if file_extension == '.tsv':\n                        df = pd.read_csv(file_path, encoding=encoding, sep='\\t')\n                    else:\n                        df = pd.read_csv(file_path, encoding=encoding)\n            else:\n                return f\"Error: Unsupported file format '{file_extension}'. Supported formats are: .csv, .txt, .tsv, .xlsx, .xls, .xlsm, .xlsb\"\n            \n            # Use filename as name if none provided\n            if name is None:\n                name = os.path.basename(file_path).split('.')[0]\n            \n            # Store the dataframe\n            self.dataframes[name] = df\n            self.current_df = name\n            \n            encoding_info = f\" using encoding: {encoding}\" if file_type == \"CSV\" and encoding else \"\"\n            return f\"Successfully loaded '{name}' ({file_type}) with {df.shape[0]} rows and {df.shape[1]} columns{encoding_info}.\"\n        \n        except Exception as e:\n            return f\"Error loading data: {str(e)}\"\n\n    def get_dataframe_info(self, name=None):\n        \"\"\"Get information about a loaded dataframe.\"\"\"\n        # Use specified name or current dataframe\n        df_name = name if name else self.current_df\n        \n        if not df_name or df_name not in self.dataframes:\n            return \"No dataframe selected or specified dataframe not found.\"\n        \n        df = self.dataframes[df_name]\n        \n        # Collect information\n        info = {\n            \"name\": df_name,\n            \"shape\": df.shape,\n            \"columns\": list(df.columns),\n            \"dtypes\": {col: str(dtype) for col, dtype in zip(df.columns, df.dtypes)},\n            \"sample\": df.head(3).to_dict()\n        }\n        \n        return info\n    \n    def list_dataframes(self):\n        \"\"\"List all loaded dataframes.\"\"\"\n        if not self.dataframes:\n            return \"No dataframes loaded.\"\n        \n        return {\n            name: {\"shape\": df.shape, \"columns\": list(df.columns)}\n            for name, df in self.dataframes.items()\n        }\n    \n    def set_current_dataframe(self, name):\n        \"\"\"Set the current active dataframe.\"\"\"\n        if name not in self.dataframes:\n            return f\"Error: Dataframe '{name}' not found.\"\n        \n        self.current_df = name\n        return f\"Current dataframe set to '{name}'.\"\n\n\n# ===== QUERY ENGINE CLASS =====\nclass QueryEngine:\n    def __init__(self, data_handler, temperature=0):\n        \"\"\"Initialize the query engine with a data handler.\"\"\"\n        self.data_handler = data_handler\n        # Initialize the language model\n        self.llm = OpenAI(temperature=temperature, openai_api_key=API_KEY)\n    \n    def get_visualization_tool(self, df):\n        \"\"\"Create a Python REPL tool with access to the dataframe and plotting libraries.\"\"\"\n        # Create locals dictionary with the dataframe and plotting libraries\n        locals_dict = {\n            \"pd\": pd, \n            \"df\": df,  # Now df is properly defined\n            \"plt\": plt, \n            \"sns\": sns,\n            \"np\": np\n        }\n        \n        # Create and return the tool\n        return PythonAstREPLTool(locals=locals_dict)\n    \n    def execute_query_with_viz(self, query, dataframe_name=None):\n        \"\"\"Execute a natural language query on a dataframe with visualization support.\"\"\"\n        # Get the dataframe to query\n        df_name = dataframe_name if dataframe_name else self.data_handler.current_df\n        \n        if not df_name or df_name not in self.data_handler.dataframes:\n            return \"No dataframe selected or specified dataframe not found.\"\n        \n        df = self.data_handler.dataframes[df_name]\n        df_info = self.data_handler.get_dataframe_info(df_name)\n        \n        try:\n            # Check if the query is asking for a visualization\n            viz_keywords = ['visualize', 'plot', 'graph', 'chart', 'display', 'show', 'histogram', 'scatter']\n            is_viz_query = any(keyword in query.lower() for keyword in viz_keywords)\n            \n            if is_viz_query:\n                # Create a plotting tool with access to this specific dataframe\n                plotting_tool = self.get_visualization_tool(df)\n                \n                # Initialize an agent with the plotting tool\n                agent = initialize_agent(\n                    [plotting_tool],\n                    self.llm,\n                    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n                    verbose=True\n                )\n                \n                # Craft a prompt that guides the agent to create a visualization\n                viz_prompt = f\"\"\"\n                Create a visual representation of the data using matplotlib or seaborn.\n                \n                Dataframe information:\n                - Name: {df_name}\n                - Shape: {df_info['shape'][0]} rows × {df_info['shape'][1]} columns\n                - Columns: {', '.join(df_info['columns'])}\n                \n                User query: {query}\n                \n                Follow these steps:\n                1. Analyze what kind of visualization would best answer the query\n                2. Create the visualization using matplotlib or seaborn\n                3. Make sure to include:\n                   - Appropriate title and axis labels\n                   - Legend if multiple series are shown\n                   - Use plt.tight_layout() for better spacing\n                   - Use plt.savefig('visualization.png') to save the visualization\n                \n                Make sure to execute the code to generate the visualization.\n                Finally, provide a brief explanation of what the visualization shows.\n                \"\"\"\n                \n                # Run the agent\n                result = agent.run(viz_prompt)\n                \n                # Return both the textual result and reference to saved visualization\n                return {\n                    'text_result': result,\n                    'visualization_path': 'visualization.png',\n                    'visualization_type': 'file'\n                }\n            \n            # For non-visualization queries, use the standard pandas agent\n            else:\n                agent = create_pandas_dataframe_agent(\n                    self.llm, \n                    df, \n                    verbose=True,\n                    allow_dangerous_code=True\n                )\n                \n                # Enhanced query with context\n                enhanced_query = f\"\"\"\n                Working with dataframe: {df_name}\n                \n                Dataframe information:\n                - Shape: {df_info['shape'][0]} rows × {df_info['shape'][1]} columns\n                - Columns: {', '.join(df_info['columns'])}\n                \n                User query: {query}\n                \n                Please provide:\n                1. A clear answer to the query\n                2. Any calculations or reasoning used\n                3. A brief explanation of the result\n                \"\"\"\n                \n                # Run the query\n                result = agent.run(enhanced_query)\n                return {'text_result': result}\n                \n        except Exception as e:\n            return f\"Error executing query: {str(e)}\"\n    \n    def execute_multi_table_query(self, query, dataframe_names):\n        \"\"\"Execute a query that references multiple tables.\"\"\"\n        # Check if specified dataframes exist\n        missing_dfs = [name for name in dataframe_names if name not in self.data_handler.dataframes]\n        if missing_dfs:\n            return f\"Error: Dataframes not found: {', '.join(missing_dfs)}\"\n        \n        # Get dataframes and their info\n        dfs = {name: self.data_handler.dataframes[name] for name in dataframe_names}\n        dfs_info = {name: self.data_handler.get_dataframe_info(name) for name in dataframe_names}\n        \n        try:\n            # Create a combined dataframe with prefixed column names\n            combined_data = {}\n            for name, df in dfs.items():\n                for col in df.columns:\n                    combined_data[f\"{name}_{col}\"] = df[col]\n            \n            combined_df = pd.DataFrame(combined_data)\n            \n            # Create an agent with the combined dataframe\n            agent = create_pandas_dataframe_agent(\n                self.llm, \n                combined_df, \n                verbose=True,\n                allow_dangerous_code=True\n            )\n            \n            # Prepare dataframe information for the prompt\n            dfs_info_text = \"\\n\".join([\n                f\"Dataframe '{name}':\\n- Columns: {', '.join(info['columns'])}\\n- Shape: {info['shape'][0]} rows × {info['shape'][1]} columns\"\n                for name, info in dfs_info.items()\n            ])\n            \n            # Enhance the query\n            enhanced_query = f\"\"\"\n            Working with multiple dataframes: {', '.join(dataframe_names)}\n            \n            {dfs_info_text}\n            \n            I've created a combined dataframe where columns are prefixed with the dataframe name.\n            For example, to access the 'price' column from the 'products' dataframe, use 'products_price'.\n            \n            User query: {query}\n            \n            Please provide:\n            1. A clear answer to the query\n            2. Any calculations or reasoning used\n            3. A brief explanation of the result\n            \"\"\"\n            \n            # Run the query\n            result = agent.run(enhanced_query)\n            return result\n            \n        except Exception as e:\n            return f\"Error executing multi-table query: {str(e)}\"\n\n\n# ===== MAIN LLM QUERY SYSTEM CLASS =====\nclass LLMQuerySystem:\n    def __init__(self):\n        \"\"\"Initialize the LLM Query System.\"\"\"\n        self.data_handler = DataHandler()\n        self.query_engine = QueryEngine(self.data_handler)\n    \n    def list_loaded_data(self):\n        \"\"\"List all loaded dataframes.\"\"\"\n        return self.data_handler.list_dataframes()\n    \n    def load_data(self, file_path, name=None, encoding=None):\n        \"\"\"Load a data file (CSV or Excel) into the system.\"\"\"\n        return self.data_handler.load_file(file_path, name, encoding)\n\n    def set_active_dataframe(self, name):\n        \"\"\"Set the active dataframe for queries.\"\"\"\n        return self.data_handler.set_current_dataframe(name)\n    \n    def execute_query(self, query, dataframe=None):\n        \"\"\"Execute a natural language query on a dataframe.\"\"\"\n        return self.query_engine.execute_query(query, dataframe)\n    \n    def execute_multi_dataframe_query(self, query, dataframes):\n        \"\"\"Execute a query across multiple dataframes.\"\"\"\n        return self.query_engine.execute_multi_table_query(query, dataframes)\n    \n    def get_dataframe_sample(self, name=None, rows=5):\n        \"\"\"Get a sample of rows from a dataframe.\"\"\"\n        df_name = name if name else self.data_handler.current_df\n        \n        if not df_name or df_name not in self.data_handler.dataframes:\n            return \"No dataframe selected or specified dataframe not found.\"\n        \n        df = self.data_handler.dataframes[df_name]\n        return df.head(rows).to_dict()\n\n    def execute_query(self, query, dataframe=None):\n        \"\"\"Execute a natural language query on a dataframe, with visualization if appropriate.\"\"\"\n        result = self.query_engine.execute_query_with_viz(query, dataframe)\n        return result\n\n\n    \n\n# ===== INTERACTIVE MODE =====\ndef run_interactive():\n    \"\"\"Run the system in interactive mode with improved user experience.\"\"\"\n    system = LLMQuerySystem()\n    \n    print(\"Welcome to the LLM Query System!\")\n    \n    loaded_files = False\n    \n    while True:\n        # If no files are loaded yet, prompt for file loading\n        if not loaded_files and not system.data_handler.dataframes:\n            print(\"\\nYou need to load at least one data file to begin.\")\n            file_paths_input = input(\"Enter file path(s) separated by commas (or 'exit' to quit): \").strip()\n            \n            if file_paths_input.lower() == 'exit':\n                print(\"Exiting system. Goodbye!\")\n                break\n                \n            # Process multiple file paths\n            file_paths = [path.strip() for path in file_paths_input.split(',')]\n            all_loaded = True\n            \n            for file_path in file_paths:\n                # Extract filename as default name\n                default_name = os.path.basename(file_path).split('.')[0]\n                name_input = input(f\"Enter name for {file_path} (press Enter to use '{default_name}'): \").strip()\n                name = name_input if name_input else default_name\n                \n                result = system.load_data(file_path, name)\n                print(result)\n                \n                if \"Error\" in result:\n                    all_loaded = False\n            \n            if all_loaded and system.data_handler.dataframes:\n                loaded_files = True\n                # Display loaded dataframes\n                print(\"\\nLoaded dataframes:\")\n                dfs = system.list_loaded_data()\n                for name, info in dfs.items():\n                    print(f\"  {name}: {info['shape'][0]} rows × {info['shape'][1]} columns\")\n                    \n                # Set active dataframe if only one is loaded\n                if len(system.data_handler.dataframes) == 1:\n                    system.set_active_dataframe(list(system.data_handler.dataframes.keys())[0])\n                    print(f\"Active dataframe set to '{system.data_handler.current_df}'\")\n                else:\n                    name = input(\"Enter name of dataframe to use as active: \").strip()\n                    print(system.set_active_dataframe(name))\n            \n        # Main command loop when files are loaded\n        else:\n            # If files are loaded, prompt for query or command\n            if system.data_handler.current_df:\n                prompt = f\"\\nEnter query for '{system.data_handler.current_df}' (or 'exit' to quit): \"\n            else:\n                prompt = \"\\nNo active dataframe selected. Enter 'exit' to quit: \"\n                \n            command = input(prompt).strip()\n            \n            # Process the command\n            if command.lower() == 'exit':\n                print(\"Exiting system. Goodbye!\")\n                break\n                \n            elif command.lower().startswith('load '):\n                parts = command[5:].strip().split(' ', 1)\n                file_path = parts[0]\n                name = parts[1] if len(parts) > 1 else None\n                print(system.load_data(file_path, name))\n                \n            elif command.lower() == 'list':\n                dfs = system.list_loaded_data()\n                if isinstance(dfs, str):\n                    print(dfs)\n                else:\n                    print(\"\\nLoaded dataframes:\")\n                    for name, info in dfs.items():\n                        print(f\"  {name}: {info['shape'][0]} rows × {info['shape'][1]} columns\")\n                \n            elif command.lower().startswith('use '):\n                name = command[4:].strip()\n                print(system.set_active_dataframe(name))\n                \n            elif command.lower().startswith('sample '):\n                parts = command[7:].strip().split(' ', 1)\n                name = parts[0] if parts and parts[0] else None\n                rows = int(parts[1]) if len(parts) > 1 else 5\n                sample = system.get_dataframe_sample(name, rows)\n                \n                # Display sample\n                if isinstance(sample, str):\n                    print(sample)\n                else:\n                    print(f\"\\nSample from dataframe:\")\n                    # Convert the dict to a more readable format\n                    for i in range(rows):\n                        if i in sample[list(sample.keys())[0]]:\n                            row_data = {col: data[i] for col, data in sample.items()}\n                            print(f\"Row {i}: {row_data}\")\n                \n\n            elif system.data_handler.current_df:\n                # Execute a query\n                print(\"\\nExecuting query...\")\n                result = system.execute_query(command)\n                \n                # Check if result is a dictionary (contains visualization)\n                if isinstance(result, dict):\n                    # Print the text result\n                    print(\"\\nResult:\")\n                    print(result.get('text_result', ''))\n                    \n                    # Check if we have a visualization\n                    if 'visualization_path' in result:\n                        print(f\"\\nVisualization created and saved to {result['visualization_path']}\")\n                            \n                else:\n                    print(\"\\nResult:\")\n                    print(result)\n\n\n# Add a simple plotting wrapper\ndef get_plot_code(df, query):\n    \"\"\"Generate code to create a matplotlib or seaborn plot based on the query.\"\"\"\n    plotting_agent = initialize_agent(\n        tools,\n        self.llm,\n        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n        verbose=True\n    )\n    \n    prompt = f\"\"\"\n    Create Python code to visualize this data with matplotlib or seaborn.\n    \n    The dataframe is called 'df' and has these columns: {', '.join(df.columns)}\n    The query is: {query}\n    \n    Return only the plotting code as a Python code block.\n    \"\"\"\n    \n    result = plotting_agent.run(prompt)\n    return result\n\n# ===== MAIN EXECUTION =====\nif __name__ == \"__main__\":\n    # Check if OPENAI_API_KEY is set\n    if not API_KEY:\n        print(\"Error: OPENAI_API_KEY not found in environment variables.\")\n        print(\"Please create a .env file with your API key or set it directly.\")\n        exit(1)\n    \n    # Run in interactive mode directly\n    run_interactive()","block_group":"13cb6816bdae4654b03ca3d7bea5457b","execution_count":3,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_160/3663680398.py:137: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n  self.llm = OpenAI(temperature=temperature, openai_api_key=API_KEY)\nWelcome to the LLM Query System!\n\nYou need to load at least one data file to begin.\nSuccessfully loaded 'the' (CSV) with 1656 rows and 14 columns using encoding: utf-8.\n\nLoaded dataframes:\n  the: 1656 rows × 14 columns\nActive dataframe set to 'the'\n\nExecuting query...\n\n\n\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n/tmp/ipykernel_160/3663680398.py:174: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n  agent = initialize_agent(\n/tmp/ipykernel_160/3663680398.py:206: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n  result = agent.run(viz_prompt)\n\u001b[32;1m\u001b[1;3m I should use matplotlib or seaborn to create a visualization.\nAction: [python_repl_ast]\nAction Input: import matplotlib.pyplot as plt\u001b[0m\nObservation: [python_repl_ast] is not a valid tool, try one of [python_repl_ast].\nThought:\u001b[32;1m\u001b[1;3m I should use matplotlib or seaborn to create a visualization.\nAction: [python_repl_ast]\nAction Input: import matplotlib.pyplot as plt\u001b[0m\nObservation: [python_repl_ast] is not a valid tool, try one of [python_repl_ast].\nThought:\u001b[32;1m\u001b[1;3m I should use matplotlib or seaborn to create a visualization.\nAction: [python_repl_ast]\nAction Input: import matplotlib.pyplot as plt\u001b[0m\nObservation: [python_repl_ast] is not a valid tool, try one of [python_repl_ast].\nThought:\u001b[32;1m\u001b[1;3m I should use matplotlib or seaborn to create a visualization.\nAction: [python_repl_ast]\nAction Input: import matplotlib.pyplot as plt\u001b[0m\nObservation: [python_repl_ast] is not a valid tool, try one of [python_repl_ast].\nThought:\u001b[32;1m\u001b[1;3m I should use matplotlib or seaborn to create a visualization.\nAction: [python_repl_ast]\nAction Input: import matplotlib.pyplot as plt\u001b[0m\nObservation: [python_repl_ast] is not a valid tool, try one of [python_repl_ast].\nThought:\u001b[32;1m\u001b[1;3m I should use matplotlib or seaborn to create a visualization.\nAction: [python_repl_ast]\nAction Input: import matplotlib.pyplot as plt\u001b[0m\nObservation: [python_repl_ast] is not a valid tool, try one of [python_repl_ast].\nThought:\u001b[32;1m\u001b[1;3m I should use matplotlib or seaborn to create a visualization.\nAction: [python_repl_ast]\nAction Input: import matplotlib.pyplot as plt\u001b[0m\nObservation: [python_repl_ast] is not a valid tool, try one of [python_repl_ast].\nThought:\u001b[32;1m\u001b[1;3m I should use matplotlib or seaborn to create a visualization.\nAction: [python_repl_ast]\nAction Input: import matplotlib.pyplot as plt\u001b[0m\nObservation: [python_repl_ast] is not a valid tool, try one of [python_repl_ast].\nThought:\u001b[32;1m\u001b[1;3m I should use matplotlib or seaborn to create a visualization.\nAction: [python_repl_ast]\nAction Input: import matplotlib.pyplot as plt\u001b[0m\nObservation: [python_repl_ast] is not a valid tool, try one of [python_repl_ast].\nThought:\u001b[32;1m\u001b[1;3m I now know the final answer\nFinal Answer: I should use matplotlib or seaborn to create a visualization.\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n\nResult:\nI should use matplotlib or seaborn to create a visualization.\n\nVisualization created and saved to visualization.png\n","output_type":"stream"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"Interrupted by user","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 505\u001b[0m\n\u001b[1;32m    502\u001b[0m     exit(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    504\u001b[0m \u001b[38;5;66;03m# Run in interactive mode directly\u001b[39;00m\n\u001b[0;32m--> 505\u001b[0m \u001b[43mrun_interactive\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[3], line 410\u001b[0m, in \u001b[0;36mrun_interactive\u001b[0;34m()\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNo active dataframe selected. Enter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to quit: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 410\u001b[0m command \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m    412\u001b[0m \u001b[38;5;66;03m# Process the command\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m command\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m:\n","File \u001b[0;32m/toolkit-cache/0.2.9/python3.10/kernel-libs/lib/python3.10/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/toolkit-cache/0.2.9/python3.10/kernel-libs/lib/python3.10/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"]}],"outputs_reference":"s3:deepnote-cell-outputs-production/82129c11-91fc-4e5c-a256-66c109d5d5f5","content_dependencies":null}],
        "metadata": {"deepnote_persisted_session":{"createdAt":"2025-03-07T12:15:33.511Z"},"deepnote_notebook_id":"a0b75b3640574f55a7b200477113d17d"},
        "nbformat": 4,
        "nbformat_minor": 0,
        "version": 0
      }